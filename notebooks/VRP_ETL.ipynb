{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0614d9bf-7a14-4cfd-a64e-af6c9e63960e",
   "metadata": {},
   "source": [
    "# VPR Data Landing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abaa2808-fa30-4835-9fd4-8a73cf70f7b0",
   "metadata": {},
   "source": [
    "# 1. Import dependencies & declare constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ec441f7-840f-46bc-ad24-3b524a91af84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import yaml\n",
    "import configparser\n",
    "\n",
    "# Add the src directory to the sys.path\n",
    "sys.path.append(os.path.abspath(os.path.join('..', 'src')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7a82708-df1f-45fa-bde0-1d3e9dd6de84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spark_session import create_spark_session\n",
    "from schemas import *\n",
    "from functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d45e8b6-4b48-4c49-b7b6-1a516b40e703",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_aws_credentials(profile_name=\"default\"):\n",
    "\n",
    "    # Load credentials from the .aws/credentials file (local development)\n",
    "    try:\n",
    "        credentials = configparser.ConfigParser()\n",
    "        credentials.read(os.path.join('..', '.aws', 'credentials'))\n",
    "        \n",
    "        logging.info(\"Successfully loaded credentials variables from .aws file.\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error loading .aws file: {e}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    aws_access_key_id = credentials[profile_name][\"aws_access_key_id\"]\n",
    "    aws_secret_access_key = credentials[profile_name][\"aws_secret_access_key\"]\n",
    "\n",
    "    if not aws_access_key_id or not aws_secret_access_key:\n",
    "        logging.error(\"AWS credentials not found.\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    return aws_access_key_id, aws_secret_access_key\n",
    "\n",
    "aws_access_key_id, aws_secret_access_key = load_aws_credentials()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3176609d-51a9-4012-8773-e733d8b51a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the YAML configuration file\n",
    "with open('../config/config.yml', 'r') as file:\n",
    "    config = yaml.safe_load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ed4acd1-9469-4295-a4fc-f1e60f09da89",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUCKET_NAME = config[\"paths\"][\"BUCKET_NAME\"]\n",
    "RAW = config[\"paths\"][\"RAW\"]\n",
    "ORDERS = config[\"paths\"][\"ORDERS\"]\n",
    "\n",
    "BRONZE = config[\"paths\"][\"BRONZE\"]\n",
    "SILVER = config[\"paths\"][\"SILVER\"]\n",
    "GOLD = config[\"paths\"][\"GOLD\"]\n",
    "\n",
    "ADDRESS_DATA = config[\"raw_data\"][\"ADDRESS_DATA\"]\n",
    "CLIENTS_DATA = config[\"raw_data\"][\"CLIENTS_DATA\"]\n",
    "PRODUCTS_DATA = config[\"raw_data\"][\"PRODUCTS_DATA\"]\n",
    "\n",
    "DATABASE_NAME = \"vpr-optimizer-platforom_db\"\n",
    "\n",
    "ADDRESS_TABLE = config[\"table_names\"][\"ADDRESS_TABLE\"]\n",
    "CLIENTS_TABLE = config[\"table_names\"][\"CLIENTS_TABLE\"]\n",
    "CLIENTS_ADDRESS_TABLE = config[\"table_names\"][\"CLIENTS_ADDRESS_TABLE\"]\n",
    "PRODUCTS_TABLE = config[\"table_names\"][\"PRODUCTS_TABLE\"]\n",
    "PACKAGE_TABLE = config[\"table_names\"][\"PACKAGE_TABLE\"]\n",
    "\n",
    "RAW_ADDRESS_PATH = os.path.join(BUCKET_NAME, RAW, ADDRESS_DATA)\n",
    "RAW_CIENTS_PATH = os.path.join(BUCKET_NAME, RAW, CLIENTS_DATA)\n",
    "RAW_PRODUCTS_PATH = os.path.join(BUCKET_NAME, RAW, PRODUCTS_DATA)\n",
    "\n",
    "BRONZE_ADDRESS_PATH = os.path.join(BUCKET_NAME, ORDERS, BRONZE, ADDRESS_TABLE)\n",
    "BRONZE_CLIENTS_PATH = os.path.join(BUCKET_NAME, ORDERS, BRONZE, CLIENTS_TABLE)\n",
    "BRONZE_PRODUCTS_PATH = os.path.join(BUCKET_NAME, ORDERS, BRONZE, PRODUCTS_TABLE)\n",
    "\n",
    "\n",
    "SILVER_ADDRESS_PATH = os.path.join(BUCKET_NAME, ORDERS, SILVER, ADDRESS_TABLE)\n",
    "SILVER_CLIENTS_PATH = os.path.join(BUCKET_NAME, ORDERS, SILVER, CLIENTS_TABLE)\n",
    "SILVER_PRODUCTS_PATH = os.path.join(BUCKET_NAME, ORDERS, SILVER, PRODUCTS_TABLE)\n",
    "\n",
    "GOLD_CLIENTS_ADDRESS_PATH = os.path.join(BUCKET_NAME, ORDERS, GOLD, CLIENTS_ADDRESS_TABLE)\n",
    "GOLD_PRODUCTS_PATH = os.path.join(BUCKET_NAME, ORDERS, GOLD, PRODUCTS_TABLE)\n",
    "GOLD_PACKAGE_PATH = os.path.join(BUCKET_NAME, ORDERS, GOLD, PACKAGE_TABLE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687009f1-ea46-42f6-a79b-d6d19e0ffae5",
   "metadata": {},
   "source": [
    "# 2. Initialize Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8730b665-4a98-4d62-9982-c89ea6760711",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/09/21 23:28:22 WARN Utils: Your hostname, Miguels-MacBook-Air.local resolves to a loopback address: 127.0.0.1; using 192.168.0.16 instead (on interface en0)\n",
      "24/09/21 23:28:22 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/Users/miguelgranica/Documents/MBIT-DE/vpr-data_landing/.venv/lib/python3.10/site-packages/pyspark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /Users/miguelgranica/.ivy2/cache\n",
      "The jars for the packages stored in: /Users/miguelgranica/.ivy2/jars\n",
      "io.delta#delta-spark_2.12 added as a dependency\n",
      "org.apache.hadoop#hadoop-aws added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-4937df64-2f21-4104-b8e2-58d80ddc1992;1.0\n",
      "\tconfs: [default]\n",
      "\tfound io.delta#delta-spark_2.12;3.2.0 in central\n",
      "\tfound io.delta#delta-storage;3.2.0 in central\n",
      "\tfound org.antlr#antlr4-runtime;4.9.3 in central\n",
      "\tfound org.apache.hadoop#hadoop-aws;3.3.1 in central\n",
      "\tfound com.amazonaws#aws-java-sdk-bundle;1.11.901 in central\n",
      "\tfound org.wildfly.openssl#wildfly-openssl;1.0.7.Final in central\n",
      ":: resolution report :: resolve 129ms :: artifacts dl 4ms\n",
      "\t:: modules in use:\n",
      "\tcom.amazonaws#aws-java-sdk-bundle;1.11.901 from central in [default]\n",
      "\tio.delta#delta-spark_2.12;3.2.0 from central in [default]\n",
      "\tio.delta#delta-storage;3.2.0 from central in [default]\n",
      "\torg.antlr#antlr4-runtime;4.9.3 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-aws;3.3.1 from central in [default]\n",
      "\torg.wildfly.openssl#wildfly-openssl;1.0.7.Final from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   6   |   0   |   0   |   0   ||   6   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-4937df64-2f21-4104-b8e2-58d80ddc1992\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 6 already retrieved (0kB/3ms)\n",
      "24/09/21 23:28:52 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "spark = create_spark_session(aws_access_key_id, aws_secret_access_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e483a57-e8f4-438b-a32c-da8b47a48af0",
   "metadata": {},
   "source": [
    "# 3. Medallion Architecure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b489c29c-3ca1-4e14-bdf9-d8de6188d350",
   "metadata": {},
   "source": [
    "## 3.1 Bronze Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "649dc958-4e83-466e-aaa6-4b80263a10ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/09/21 23:28:54 WARN MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties\n"
     ]
    }
   ],
   "source": [
    "df_address_raw = read_file(spark, RAW_ADDRESS_PATH, \"json\", addresses_schema)\n",
    "df_clients_raw = read_file(spark, RAW_CIENTS_PATH, \"json\", clients_schema)\n",
    "df_products_raw = read_file(spark, RAW_PRODUCTS_PATH, \"json\", products_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "649e1b06-d634-47e7-8b2f-5dd1e91b66e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "write_df(df_address_raw, BRONZE_ADDRESS_PATH)\n",
    "write_df(df_clients_raw, BRONZE_CLIENTS_PATH)\n",
    "write_df(df_products_raw, BRONZE_PRODUCTS_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99cef1a-5752-404c-aaa0-58ef23366ada",
   "metadata": {},
   "source": [
    "## 3.2 Silver Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad101a55-93e3-4360-945c-d2eb11901413",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_address_bronze = read_file(spark, BRONZE_ADDRESS_PATH, \"parquet\", addresses_schema)\n",
    "df_clients_bronze = read_file(spark, BRONZE_CLIENTS_PATH, \"parquet\", clients_schema)\n",
    "df_products_bronze = read_file(spark, BRONZE_PRODUCTS_PATH, \"parquet\", products_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "82c5fce8-a7d6-4155-8c56-3bc8a33a0165",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "write_df(transform_addresses_bronze_to_silver(df_address_bronze), SILVER_ADDRESS_PATH)\n",
    "write_df(transform_clients_bronze_to_silver(df_clients_bronze), SILVER_CLIENTS_PATH)\n",
    "write_df(transform_products_bronze_to_silver(df_products_bronze), SILVER_PRODUCTS_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6a6c62-24f5-4825-9128-4be64a0c8054",
   "metadata": {},
   "source": [
    "## 3.3 Gold Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5b497a15-00b3-4e7a-9bd1-5e8cb05c5f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_address_silver = read_file(spark, SILVER_ADDRESS_PATH, \"parquet\", silver_address_schema)\n",
    "df_clients_silver = read_file(spark, SILVER_CLIENTS_PATH, \"parquet\", silver_clients_schema)\n",
    "df_products_silver = read_file(spark, SILVER_PRODUCTS_PATH, \"parquet\", silver_products_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a0bae6e5-370a-430d-8c6e-ef2d1071c338",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "write_df(transform_clients_addresses_silver_to_gold(df_clients_silver, df_address_silver), GOLD_CLIENTS_ADDRESS_PATH)\n",
    "write_df(transform_products_silver_to_gold(df_products_silver), GOLD_PRODUCTS_PATH, file_type=\"delta\")\n",
    "write_df(transform_packages_silver_to_gold(df_products_silver), GOLD_PACKAGE_PATH, file_type=\"delta\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
